---
title: "HW10: Importing"
author: "FIRSTNAME LASTNAME"
date: "`r format(Sys.time(), '%B %d, %Y')`"
time: "`r format(Sys.time(), '%H:%M')`"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


##Instructions
Use this template to load your candidate's campaign finance data as well as the voter registration and history data for the counties in which your candidate is running. Upload your edited .Rmd file to Sakai.

###We have a new package to install and load: janitor
```{r}
#install.packages("janitor")
library(janitor)
```


###Load the tidyverse package(s)
```{r}
#install.packages("tidyverse")
library(tidyverse)
```




###Yancey County voter registration. Replace with your relevant counties.
Use this URL to set all correct data types: https://s3.amazonaws.com/dl.ncsbe.gov/data/layout_ncvoter_ncvhis.txt
```{r}
temp <- tempfile()

download.file("https://s3.amazonaws.com/dl.ncsbe.gov/data/ncvoter100.zip",temp)

voters_yancey <- read_delim(unz(temp, "ncvoter100.txt"),
                            "\t", 
                            escape_double = FALSE, 
                            trim_ws = TRUE, 
                            #locale = locale(encoding = "UTF8"),
                            na = c("", " "), 
                            col_types = cols(.default = "c", 
                            birth_age = "i",
                            birth_year = "i")
)


unlink(temp)







```

###2019 Municipal Election Results
```{r}
temp <- tempfile()

download.file("https://s3.amazonaws.com/dl.ncsbe.gov/ENRS/2019_11_05/results_pct_20191105.zip",temp)

results2019 <- read_delim(unz(temp, "results_pct_20191105.txt"),
                          "\t", 
                          escape_double = FALSE,
                          trim_ws = TRUE, 
                          col_types = cols(
                          `Election Date`  = col_date("%m/%d/%Y"),
                          `Contest Group ID` = col_character(),
                          `Choice Party` = col_character()
                          )) %>%
#clean_names is from the janitor package
  clean_names() %>%
#This next line deals with an issue I was having with "embedded nulls". I did try setting the locale inside read_delim, but it did not fix them problem. This line seems to do the trick... 
mutate(choice_party = parse_character(choice_party, locale = locale(encoding = "ISO-8859-2")))

#I used this line to determine the encoding of the file. 
#guess_encoding("results_pct_20181106.txt", n_max = -1, threshold = 0.2)

#results2018$`Choice Party`<- parse_character(results2018$`Choice Party`, locale = locale(encoding = "ISO-8859-2"))

unlink(temp)
```

###Yancey County voter history. Replace with your counties.
```{r}
temp <- tempfile()

download.file("https://s3.amazonaws.com/dl.ncsbe.gov/data/ncvhis100.zip",temp)

vhis_yancey <- read_delim(unz(temp, "ncvhis100.txt"), 
    "\t", escape_double = FALSE, col_types = cols(county_id = col_character(), 
        election_lbl = col_date(format = "%m/%d/%Y"), 
        voted_county_id = col_character()), 
    trim_ws = TRUE)

unlink(temp)
```

###Candidate filing
```{r}
candidates2020 <- read_csv("https://s3.amazonaws.com/dl.ncsbe.gov/Elections/2020/Candidate%20Filing/Candidate_Listing_2020.csv", 
    col_types = cols(candidacy_dt = col_date(format = "%m/%d/%Y"), 
        election_dt = col_date(format = "%m/%d/%Y")))
```


###Campaign Finance. Replace with your candidate.
```{r}

url <- "https://cf.ncsbe.gov/CFOrgLkup/ExportDetailResults/?ReportID=168216&Type=REC&Title=Cooper%20for%20North%20Carolina%20-%202019%20Mid%20Year%20Semi-Annual"

#read_csv() does not do a great job here guessing the correct col_types, so we have to define them explicitly.

cooper_rcpts_2019A <- read_csv(url, 
    col_types = cols(
      `Account Abbr` = col_character(), 
        City = col_character(), 
      `Country Name` = col_character(), 
        Date = col_date(format = "%m/%d/%Y"), 
        Description = col_character(), 
      `Employers Name` = col_character(), 
        `Full Zip` = col_character(), 
      `Outside US Postal Code` = col_character(), 
        Profession = col_character(), 
      Purpose = col_character(), 
        State = col_character(), 
      `Street 1` = col_character(), 
        `Street 2` = col_character()),
    skip = 1)

#Finally, we should rename the columns to remove spaces and generally promote brevity.

names(cooper_rcpts_2019A) <- c("date","prior","donor","street1","street2","city","state","zip","country","postal","profession","employer","purpose","type","account","payment_form","description","amount","sum_to_date")

```


#Lobbyists. (Tab delimited). 
```{r}
#temp <- tempfile()

#lobbyists URL is dynamic, so we will not use.
#download.file("https://sosnc.gov/imaging/Dime/20191219/a882197628a9427f936b988405748d00.zip",temp)



#lobbyists2020 <- read_delim("read_delim(unz(temp,", 
#    "\t", escape_double = FALSE, col_types = #cols(LobbyAddress2 = col_character(), 
#        PrinTitle = col_character()), trim_ws = TRUE)

#unlink(temp)

#You will see an error message that should concern you. It says it was getting more data than expected. But if you poke around in the file a bit with a text editor, you will see that there is an etra "tab" and the end of all the data lines... but not in the first row, which gives us our column headers. We see in the global environment that this dataframe has the 23 columns we would expect, so for now we can ignore this error. But it should lurk in the back of our head as the first place to look if we start seeing errors in our analysis.

```




